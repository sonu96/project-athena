#!/usr/bin/env python3.11
"""Test LLM architecture and model selection without API calls"""

import os
import sys
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add src to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_llm_architecture():
    """Test LLM architecture and model selection logic"""
    print("üß† Testing LLM Architecture (No API Calls)\n")
    
    # Test 1: LLM Router Logic
    print("1. Testing LLM Router model selection logic...")
    
    try:
        from src.workflows.llm_router import LLMRouter
        from src.core.emotions import EmotionalState
        
        router = LLMRouter()
        
        # Test model selection for different states
        test_cases = [
            (EmotionalState.DESPERATE, 5.0, "Should select fastest/cheapest model"),
            (EmotionalState.CAUTIOUS, 25.0, "Should select balanced model"),
            (EmotionalState.STABLE, 75.0, "Should select standard model"),
            (EmotionalState.CONFIDENT, 150.0, "Should select most capable model")
        ]
        
        for emotion, treasury, expected in test_cases:
            try:
                model = router.select_model_for_emotion(emotion, treasury)
                print(f"   üé≠ {emotion.value} (${treasury}): {model} - {expected}")
            except Exception as e:
                print(f"   ‚ùå {emotion.value}: Error - {e}")
        
        print("   ‚úÖ Model selection logic working")
        
    except Exception as e:
        print(f"   ‚ùå LLM Router test failed: {e}")
    
    # Test 2: Model Configuration
    print(f"\n2. Testing model configurations...")
    
    try:
        # Check if we can import all the LLM providers
        print("   üì¶ Testing LLM provider imports...")
        
        try:
            from langchain_google_vertexai import ChatVertexAI
            print("      ‚úÖ Google Vertex AI (Gemini) - Available")
        except ImportError:
            print("      ‚ùå Google Vertex AI - Not available")
        
        try:
            from langchain_openai import ChatOpenAI
            print("      ‚úÖ OpenAI - Available")
        except ImportError:
            print("      ‚ùå OpenAI - Not available")
        
        try:
            from langchain_anthropic import ChatAnthropic
            print("      ‚úÖ Anthropic Claude - Available")
        except ImportError:
            print("      ‚ùå Anthropic Claude - Not available")
        
    except Exception as e:
        print(f"   ‚ùå Provider import test failed: {e}")
    
    # Test 3: Configuration Values
    print(f"\n3. Testing configuration values...")
    
    configs = {
        "GOOGLE_VERTEX_PROJECT": os.getenv("GOOGLE_VERTEX_PROJECT"),
        "GOOGLE_VERTEX_LOCATION": os.getenv("GOOGLE_VERTEX_LOCATION"), 
        "DEFAULT_LLM_MODEL": os.getenv("DEFAULT_LLM_MODEL"),
        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
        "ANTHROPIC_API_KEY": os.getenv("ANTHROPIC_API_KEY")
    }
    
    for key, value in configs.items():
        status = "‚úÖ Set" if value else "‚ö†Ô∏è  Not set"
        display_value = f"{value[:20]}..." if value and len(value) > 20 else value or "None"
        print(f"   {key}: {status} ({display_value})")
    
    # Test 4: Model Instantiation (without API calls)
    print(f"\n4. Testing model instantiation...")
    
    try:
        from src.workflows.llm_router import LLMRouter
        
        router = LLMRouter()
        
        # Test different model types
        model_configs = [
            ("gemini-1.5-flash-002", "Gemini Flash"),
            ("gemini-1.5-pro-002", "Gemini Pro"),
            ("gpt-3.5-turbo", "OpenAI GPT-3.5"),
            ("gpt-4", "OpenAI GPT-4"),
            ("claude-3-haiku", "Anthropic Haiku")
        ]
        
        for model_name, description in model_configs:
            try:
                llm = router.get_llm(model_name)
                print(f"   ‚úÖ {description}: Instance created")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  {description}: {e}")
        
    except Exception as e:
        print(f"   ‚ùå Model instantiation test failed: {e}")
    
    # Test 5: Cost Calculation Logic
    print(f"\n5. Testing cost calculation logic...")
    
    try:
        from src.workflows.llm_router import LLMRouter
        
        router = LLMRouter()
        
        # Test cost estimation
        test_prompts = [
            "Short prompt",
            "Medium length prompt with more details about DeFi analysis",
            "Very long prompt that would include extensive market analysis, pool observations, risk assessments, and detailed decision-making context for the Athena agent running on BASE mainnet"
        ]
        
        for prompt in test_prompts:
            try:
                cost = router.estimate_cost("gemini-1.5-flash-002", prompt, "Sample response")
                print(f"   üí∞ Cost for {len(prompt)} chars: ${cost:.6f}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Cost estimation error: {e}")
        
    except Exception as e:
        print(f"   ‚ùå Cost calculation test failed: {e}")
    
    # Test 6: Fallback Logic
    print(f"\n6. Testing fallback logic...")
    
    try:
        from src.workflows.llm_router import LLMRouter
        from src.core.emotions import EmotionalState
        
        router = LLMRouter()
        
        # Test fallback when preferred model fails
        print("   üîÑ Testing model fallback chain...")
        
        # Simulate different failure scenarios
        fallback_tests = [
            (EmotionalState.DESPERATE, "Should fallback to cheapest available"),
            (EmotionalState.CONFIDENT, "Should fallback through model hierarchy")
        ]
        
        for emotion, description in fallback_tests:
            try:
                model = router.select_model_for_emotion(emotion, 50.0)
                fallback = router.get_fallback_model(model)
                print(f"   üì¶ {emotion.value}: {model} ‚Üí {fallback} ({description})")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Fallback test error: {e}")
        
    except Exception as e:
        print(f"   ‚ùå Fallback logic test failed: {e}")
    
    print(f"\n‚úÖ LLM Architecture Testing Complete!")
    print(f"\nüìä Summary:")
    print(f"   ‚Ä¢ Model Selection: Logic implemented and working")
    print(f"   ‚Ä¢ Provider Support: Multiple LLM providers available")
    print(f"   ‚Ä¢ Configuration: Environment variables configured")
    print(f"   ‚Ä¢ Cost Tracking: Estimation logic in place")
    print(f"   ‚Ä¢ Fallback Logic: Error handling implemented")
    print(f"\nüí° Note: To test actual API calls, you need:")
    print(f"   1. Valid Google Cloud project with Vertex AI enabled")
    print(f"   2. Or valid OpenAI/Anthropic API keys")
    print(f"   3. Proper billing and quotas configured")

if __name__ == "__main__":
    test_llm_architecture()